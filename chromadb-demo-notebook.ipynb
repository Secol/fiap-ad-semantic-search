{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bade45d5",
   "metadata": {},
   "source": [
    "# ChromaDB: Demonstração de Busca Semântica\n",
    "\n",
    "## Busca Semântica em Documentos de Texto\n",
    "\n",
    "Este notebook demonstra de forma didática as capacidades do **ChromaDB** para realizar busca semântica em documentos de texto em português.\n",
    "\n",
    "### Objetivos desta demonstração:\n",
    "\n",
    "1. **Processar documentos** - Dividir textos em chunks (parágrafos)\n",
    "2. **Gerar embeddings** - Transformar texto em vetores numéricos\n",
    "3. **Armazenar no ChromaDB** - Persistir embeddings e metadados\n",
    "4. **Busca semântica** - Encontrar documentos semanticamente similares\n",
    "\n",
    "### Recursos:\n",
    "\n",
    "- [ChromaDB Documentation](https://docs.trychroma.com/)\n",
    "- [Sentence Transformers](https://www.sbert.net/)\n",
    "\n",
    "\n",
    "## 1. Instalação e Configuração\n",
    "\n",
    "Instalar as dependências necessárias para o Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87b73c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação de dependências\n",
    "!pip install -q chromadb sentence-transformers numpy pandas matplotlib seaborn plotly scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b2af2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.manifold import TSNE\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuração de visualização\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7159b8b",
   "metadata": {},
   "source": [
    "## 2. Corpus Sintético em Português\n",
    "\n",
    "Criamos um conjunto de documentos de texto em português."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fba1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_portuguese_texts():\n",
    "    \"\"\"\n",
    "    Cria textos de exemplo em português..\n",
    "    \"\"\"\n",
    "    texts = [\n",
    "        {\n",
    "            \"id\": \"001\",\n",
    "            \"title\": \"Tecnologia Brasileira em Ascensão\",\n",
    "            \"content\": \"A tecnologia brasileira está em franco crescimento. Startups de São Paulo e outras cidades brasileiras têm desenvolvido soluções inovadoras em inteligência artificial, machine learning e cloud computing. O investimento em tecnologia no Brasil cresceu 45% no último ano.\\n\\nA formação de profissionais qualificados nas universidades tem impulsionado esse setor estratégico para a economia. Programas de aceleração e incubadoras apoiam empreendedores desde a concepção da ideia até a escalabilidade do negócio.\",\n",
    "            \"category\": \"tecnologia\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"002\",\n",
    "            \"title\": \"Agricultura Sustentável no Brasil\",\n",
    "            \"content\": \"O agronegócio brasileiro está adotando práticas mais sustentáveis. Agricultores utilizam técnicas de agricultura de precisão, com drones e sensores IoT para monitorar plantações. O Brasil é líder mundial na produção de alimentos orgânicos certificados.\\n\\nA tecnologia blockchain começa a ser usada para rastreabilidade de produtos agrícolas. Sistemas de irrigação inteligente economizam água e energia, respondendo a condições climáticas em tempo real.\",\n",
    "            \"category\": \"agronegocio\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"003\",\n",
    "            \"title\": \"Educação Digital Transforma Ensino\",\n",
    "            \"content\": \"A educação digital revoluciona o ensino no Brasil. Plataformas online democratizam o acesso ao conhecimento em regiões remotas. Professores utilizam ferramentas de gamificação para engajar alunos.\\n\\nA pandemia acelerou a adoção de metodologias ativas nas instituições de ensino. Ferramentas de videoconferência tornaram-se essenciais no ambiente educacional.\"\"\",\n",
    "            \"category\": \"educacao\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"004\",\n",
    "            \"title\": \"Energia Renovável Avança no País\",\n",
    "            \"content\": \"O Brasil amplia sua matriz de energia renovável. Parques eólicos no Nordeste geram eletricidade limpa para milhões de residências. Painéis solares se popularizam com financiamentos acessíveis.\\n\\nPesquisas desenvolvem tecnologias de hidrogênio verde. O país tem recursos naturais abundantes para liderar a transição energética global.\",\n",
    "            \"category\": \"energia\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"005\",\n",
    "            \"title\": \"Inteligência Artificial na Saúde\",\n",
    "            \"content\": \"A inteligência artificial transforma a saúde brasileira. Algoritmos auxiliam médicos no diagnóstico precoce de doenças. Telemedicina conecta especialistas a pacientes em áreas remotas.\\n\\nPesquisadores desenvolvem modelos de IA adaptados para doenças tropicais. Sistemas de predição identificam surtos epidemiológicos precocemente.\",\n",
    "            \"category\": \"saude\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"006\",\n",
    "            \"title\": \"Fintechs Democratizam Serviços\",\n",
    "            \"content\": \"Fintechs brasileiras lideram inovação na América Latina. Aplicativos de pagamento digital atendem milhões sem conta bancária tradicional. PIX revolucionou pagamentos instantâneos.\\n\\nOpen banking permite integração entre instituições. A regulação do Banco Central impulsiona competição e beneficia consumidores.\",\n",
    "            \"category\": \"financas\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"007\",\n",
    "            \"title\": \"Mobilidade Urbana Inteligente\",\n",
    "            \"content\": \"Tecnologia revoluciona a mobilidade urbana. Aplicativos de transporte compartilhado reduzem uso de veículos particulares. Sistemas inteligentes otimizam fluxo de trânsito.\\n\\nPlataformas digitais integram diferentes modais de transporte. Análise de dados em tempo real melhora planejamento de rotas.\",\n",
    "            \"category\": \"mobilidade\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"008\",\n",
    "            \"title\": \"E-commerce em Expansão\",\n",
    "            \"content\": \"O comércio eletrônico brasileiro cresce exponencialmente. Pequenos comerciantes vendem em marketplaces nacionais. Inteligência artificial personaliza recomendações de produtos.\\n\\nLogística avançada garante entregas rápidas. Live commerce une entretenimento e vendas online.\",\n",
    "            \"category\": \"comercio\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"009\",\n",
    "            \"title\": \"Cibersegurança em Foco\",\n",
    "            \"content\": \"Cibersegurança torna-se prioridade empresarial. Ataques cibernéticos aumentam em sofisticação. Empresas investem em firewalls e autenticação multifator.\\n\\nLei Geral de Proteção de Dados impõe regras rigorosas. Startups desenvolvem tecnologias nacionais de segurança digital.\",\n",
    "            \"category\": \"seguranca\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"010\",\n",
    "            \"title\": \"Cloud Computing Transforma Negócios\",\n",
    "            \"content\": \"Computação em nuvem revoluciona negócios. Empresas migram infraestrutura reduzindo custos. SaaS democratiza acesso a softwares empresariais.\\n\\nProvedores globais instalam datacenters no Brasil. Multi-cloud oferece flexibilidade e resiliência.\",\n",
    "            \"category\": \"cloud\"\n",
    "        }\n",
    "    ]\n",
    "    return texts\n",
    "\n",
    "# Carregar documentos\n",
    "documents = create_sample_portuguese_texts()\n",
    "\n",
    "print(f\"Total de documentos: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8a0b18",
   "metadata": {},
   "source": [
    "## 3. Processamento e Chunking de Documentos\n",
    "\n",
    "**Chunking** é o processo de dividir documentos grandes em pedaços menores. Vamos dividir cada documento por **parágrafos**.\n",
    "\n",
    "### Por que fazer chunking?\n",
    "\n",
    "- **Precisão**: Chunks menores melhoram a precisão da busca semântica\n",
    "- **Performance**: Vetores menores são mais eficientes para comparação\n",
    "- **Contexto**: Cada parágrafo mantém contexto semântico coerente\n",
    "\n",
    "### Estratégia:\n",
    "Vamos dividir cada documento pelos caracteres `\\n\\n` (quebra de linha dupla), que separam parágrafos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dec7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_documents(documents: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Divide documentos em chunks (parágrafos).\n",
    "    \n",
    "    Args:\n",
    "        documents: Lista de documentos originais\n",
    "        \n",
    "    Returns:\n",
    "        Lista de chunks com metadados preservados\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    \n",
    "    for doc in documents:\n",
    "        # Divide o conteúdo por parágrafos (quebra dupla de linha)\n",
    "        paragraphs = [p.strip() for p in doc['content'].split('\\n\\n') if p.strip()]\n",
    "        \n",
    "        # Cria um chunk para cada parágrafo\n",
    "        for idx, paragraph in enumerate(paragraphs):\n",
    "            chunk = {\n",
    "                'chunk_id': f\"{doc['id']}_p{idx+1}\",  # ID único do chunk\n",
    "                'doc_id': doc['id'],                   # ID do documento original\n",
    "                'title': doc['title'],\n",
    "                'category': doc['category'],\n",
    "                'paragraph_num': idx + 1,\n",
    "                'total_paragraphs': len(paragraphs),\n",
    "                'content': paragraph,\n",
    "                'char_count': len(paragraph)\n",
    "            }\n",
    "            chunks.append(chunk)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Processar documentos\n",
    "chunks = chunk_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bd7349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processar documentos\n",
    "chunks = chunk_documents(documents)\n",
    "\n",
    "print(f\"Chunking concluído.\")\n",
    "print(f\"Estatísticas:\")\n",
    "print(f\"\\t- Documentos originais: {len(documents)}\")\n",
    "print(f\"\\t- Total de chunks: {len(chunks)}\")\n",
    "print(f\"\\t- Média de chunks por documento: {len(chunks)/len(documents):.1f}\")\n",
    "\n",
    "# Mostrar exemplo de documento ANTES do chunking\n",
    "print(\"\\n\\nANTES DO CHUNKING - Documento Original:\\n\")\n",
    "print(f\"ID: {documents[0]['id']}\")\n",
    "print(f\"Título: {documents[0]['title']}\")\n",
    "print(f\"Conteúdo completo:\\n{documents[0]['content']}\")\n",
    "\n",
    "# Mostrar os chunks gerados deste documento\n",
    "print(\"\\n\\nDEPOIS DO CHUNKING - Chunks Gerados:\")\n",
    "doc_chunks = [c for c in chunks if c['doc_id'] == '001']\n",
    "for chunk in doc_chunks:\n",
    "    print(f\"\\n\\t- Chunk ID: {chunk['chunk_id']}\")\n",
    "    print(f\"\\t- Parágrafo: {chunk['paragraph_num']}/{chunk['total_paragraphs']}\")\n",
    "    print(f\"\\t- Tamanho: {chunk['char_count']} caracteres\")\n",
    "    print(f\"\\t- Conteúdo: {chunk['content'][:100]}...\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e282a2",
   "metadata": {},
   "source": [
    "## 4. Geração de Embeddings\n",
    "\n",
    "Vamos transformar texto em **vetores numéricos** (embeddings) usando o modelo **Sentence-BERT**.\n",
    "\n",
    "### O que são Embeddings?\n",
    "\n",
    "Embeddings são representações numéricas de texto que capturam o **significado semântico**:\n",
    "- Textos similares têm vetores próximos no espaço vetorial\n",
    "- Cada dimensão captura diferentes aspectos do significado\n",
    "- Permitem comparação matemática entre textos\n",
    "\n",
    "### Modelo Utilizado:\n",
    "[**`paraphrase-multilingual-MiniLM-L12-v2`**](https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2)\n",
    "- Otimizado para português e outras línguas\n",
    "- Gera vetores de **384 dimensões**\n",
    "- Treinado em milhões de pares de sentenças"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89afc806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar modelo de embeddings\n",
    "embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "# Informações sobre o modelo\n",
    "print(f\"Informações do Modelo:\")\n",
    "print(f\"\\t- Dimensões do vetor: {embedding_model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818b62ce",
   "metadata": {},
   "source": [
    "### Demonstração: Texto para Vetor\n",
    "\n",
    "Vamos ver **passo a passo** como um chunk de texto é transformado em vetor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d4c12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar um chunk de exemplo\n",
    "example_chunk = chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945df3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ANTES: TEXTO ORIGINAL\\n\")\n",
    "print(f\"\\t- Chunk ID: {example_chunk['chunk_id']}\")\n",
    "print(f\"\\t- Categoria: {example_chunk['category']}\")\n",
    "print(f\"\\t- Tipo de dado: {type(example_chunk['content'])}\")\n",
    "print(f\"\\nConteúdo:\")\n",
    "print(f'\"{example_chunk[\"content\"]}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8644ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar embedding\n",
    "embedding = embedding_model.encode(example_chunk['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f5870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DEPOIS: VETOR DE EMBEDDING\")\n",
    "print(f\"\\t- Tipo de dado: {type(embedding)}\")\n",
    "print(f\"\\t- Dimensões: {embedding.shape}\")\n",
    "print(f\"\\nPrimeiros 10 valores do vetor:\")\n",
    "print(embedding[:10])\n",
    "print(f\"\\nÚltimos 10 valores do vetor:\")\n",
    "print(embedding[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d10808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribuição dos valores\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.hist(embedding, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribuição dos Valores no Vetor de Embedding', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Valor')\n",
    "plt.ylabel('Frequência')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9798db",
   "metadata": {},
   "source": [
    "### Interpretação:\n",
    "- Cada número representa uma `feature` semântica abstraída do texto\n",
    "- Textos similares terão vetores com valores próximos\n",
    "- A distância entre vetores mede similaridade semântica\n",
    "\n",
    "### Gerando Embeddings para Todos os Chunks\n",
    "\n",
    "Agora vamos processar todos os chunks e gerar seus embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e52d861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar embeddings para todos os chunks\n",
    "print(\"Gerando embeddings para todos os chunks...\")\n",
    "texts_to_encode = [chunk['content'] for chunk in chunks]\n",
    "all_embeddings = embedding_model.encode(texts_to_encode, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8248f238",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape da matriz de embeddings: {all_embeddings.shape}\")\n",
    "print(f\"\\t- {all_embeddings.shape[0]} chunks\")\n",
    "print(f\"\\t- {all_embeddings.shape[1]} dimensões por vetor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c5e825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar embeddings aos chunks\n",
    "for chunk, embedding in zip(chunks, all_embeddings):\n",
    "    chunk['embedding'] = embedding.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b0989f",
   "metadata": {},
   "source": [
    "## 5. Inicializar ChromaDB e Criar Coleção\n",
    "\n",
    "Vamos configurar o **ChromaDB** para armazenar nossos embeddings.\n",
    "\n",
    "### O que é ChromaDB?\n",
    "\n",
    "ChromaDB é um banco de dados vetorial que:\n",
    "- Armazena embeddings eficientemente\n",
    "- Realiza buscas de similaridade rápidas\n",
    "- Mantém metadados associados aos vetores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c184c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar cliente ChromaDB (em memória para demonstração)\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "# Criar coleção\n",
    "collection_name = \"documentos_portugues\"\n",
    "\n",
    "# Deletar coleção se já existir (para re-executar o notebook)\n",
    "try:\n",
    "    chroma_client.delete_collection(collection_name)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "collection = chroma_client.create_collection(\n",
    "    name=collection_name,\n",
    "    metadata={\"description\": \"Documentos em português\", \"hnsw:space\": \"cosine\"}\n",
    ")\n",
    "\n",
    "print(f\"ChromaDB inicializado.\")\n",
    "print(f\"Coleção criada: '{collection_name}'\")\n",
    "print(f\"\\nConfigurações da coleção:\")\n",
    "print(f\"\\t- Nome: {collection.name}\")\n",
    "print(f\"\\t- Metadados: {collection.metadata}\")\n",
    "print(f\"\\t- Métrica de distância: Cosine\")\n",
    "print(f\"\\t- Quantidade de documentos: {collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aa11f3",
   "metadata": {},
   "source": [
    "### Inserindo Chunks no ChromaDB\n",
    "\n",
    "Vamos adicionar todos os chunks com seus embeddings e metadados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e956f91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dados para inserção\n",
    "ids = [chunk['chunk_id'] for chunk in chunks]\n",
    "embeddings_list = [chunk['embedding'] for chunk in chunks]\n",
    "documents_list = [chunk['content'] for chunk in chunks]\n",
    "metadatas = [\n",
    "    {\n",
    "        'doc_id': chunk['doc_id'],\n",
    "        'title': chunk['title'],\n",
    "        'category': chunk['category'],\n",
    "        'paragraph_num': chunk['paragraph_num'],\n",
    "        'char_count': chunk['char_count']\n",
    "    }\n",
    "    for chunk in chunks\n",
    "]\n",
    "\n",
    "print(\"Inserindo chunks no ChromaDB...\")\n",
    "collection.add(\n",
    "    ids=ids,\n",
    "    embeddings=embeddings_list,\n",
    "    documents=documents_list,\n",
    "    metadatas=metadatas\n",
    ")\n",
    "\n",
    "print(f\"Chunks inseridos com sucesso.\")\n",
    "print(f\"\\nEstatísticas da coleção:\")\n",
    "print(f\"\\t- Total de documentos: {collection.count()}\")\n",
    "print(f\"\\t- IDs de exemplo: {ids[:3]}\")\n",
    "print(f\"\\nO que foi armazenado:\")\n",
    "print(f\"\\t- Embeddings vetoriais ({all_embeddings.shape[1]} dimensões)\")\n",
    "print(f\"\\t- Textos originais dos chunks\")\n",
    "print(f\"\\t- Metadados (categoria, título, etc)\")\n",
    "print(f\"\\t- IDs únicos para cada chunk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d04b04",
   "metadata": {},
   "source": [
    "## 6. Busca Semântica\n",
    "\n",
    "Agora vamos realizar uma **busca semântica** e entender cada etapa do processo!\n",
    "\n",
    "### Como funciona a busca semântica?\n",
    "\n",
    "1. **Query:** Convertida em embedding\n",
    "2. **Comparação:** Calcula similaridade com todos os vetores armazenados\n",
    "3. **Ranking:** Ordena resultados por similaridade\n",
    "4. **Retorno:** Devolve os k documentos mais similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbc4a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir query de busca\n",
    "query_text = \"inteligência artificial e machine learning em hospitais\"\n",
    "\n",
    "print(\"ETAPA 1: QUERY ORIGINAL\")\n",
    "print(f'Query: \"{query_text}\"')\n",
    "print(f\"Tipo: {type(query_text)}\")\n",
    "print(f\"Tamanho: {len(query_text)} caracteres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77ba834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter query em embedding\n",
    "query_embedding = embedding_model.encode(query_text)\n",
    "\n",
    "print(\"ETAPA 2: QUERY COMO VETOR\")\n",
    "print(f\"Dimensões: {query_embedding.shape}\")\n",
    "print(f\"Primeiros 10 valores: {query_embedding[:10]}\")\n",
    "print(f\"\\nAgora a query está no mesmo 'espaço vetorial' que os documentos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc1f3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar busca no ChromaDB\n",
    "results = collection.query(\n",
    "    query_embeddings=[query_embedding.tolist()],\n",
    "    n_results=3  # Top 3 resultados mais similares\n",
    ")\n",
    "\n",
    "print(\"ETAPA 3: RESULTADOS DA BUSCA\")\n",
    "print(f\"Encontrados: {len(results['ids'][0])} resultados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf78a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar resultados detalhados\n",
    "for idx, (doc_id, document, metadata, distance) in enumerate(zip(\n",
    "    results['ids'][0],\n",
    "    results['documents'][0],\n",
    "    results['metadatas'][0],\n",
    "    results['distances'][0]\n",
    "), 1):\n",
    "    similarity_score = (1 - (distance / 2)) * 100  # Converter para porcentagem 0-100%\n",
    "    print(f\"\\nResultado #{idx}\")\n",
    "    print(f\"\\t- Chunk ID: {doc_id}\")\n",
    "    print(f\"\\t- Título: {metadata['title']}\")\n",
    "    print(f\"\\t- Categoria: {metadata['category']}\")\n",
    "    print(f\"\\t- Distância Cosine: {distance:.4f} (menor = melhor)\")\n",
    "    print(f\"\\t- Match Score: {similarity_score:.1f}%\")\n",
    "    print(f\"\\t- Conteúdo: {document[:100]}...\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d863d1b",
   "metadata": {},
   "source": [
    "### Visualizando Similaridade entre Query e Resultados\n",
    "\n",
    "Vamos calcular e visualizar as similaridades usando **cosseno**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c91b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegar embeddings dos resultados\n",
    "result_chunk_ids = results['ids'][0]\n",
    "result_embeddings = []\n",
    "\n",
    "for chunk_id in result_chunk_ids:\n",
    "    chunk = next(c for c in chunks if c['chunk_id'] == chunk_id)\n",
    "    result_embeddings.append(chunk['embedding'])\n",
    "\n",
    "result_embeddings = np.array(result_embeddings)\n",
    "\n",
    "# Calcular similaridade de cosseno\n",
    "query_emb_2d = query_embedding.reshape(1, -1)\n",
    "similarities = cosine_similarity(query_emb_2d, result_embeddings)[0]\n",
    "\n",
    "# Criar visualização\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Gráfico de barras de similaridade\n",
    "categories = [results['metadatas'][0][i]['category'] for i in range(len(similarities))]\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(similarities)))\n",
    "\n",
    "bars = ax1.barh(range(len(similarities)), similarities, color=colors)\n",
    "ax1.set_yticks(range(len(similarities)))\n",
    "ax1.set_yticklabels([f\"Resultado {i+1}\\n({cat})\" for i, cat in enumerate(categories)])\n",
    "ax1.set_xlabel('Similaridade de Cosseno', fontweight='bold')\n",
    "ax1.set_title('Similaridade: Query vs Resultados', fontweight='bold')\n",
    "ax1.set_xlim(0, 1)\n",
    "\n",
    "for i, (bar, sim) in enumerate(zip(bars, similarities)):\n",
    "    ax1.text(sim + 0.01, i, f'{sim:.4f}', va='center')\n",
    "\n",
    "# Heatmap de comparação\n",
    "comparison_matrix = np.zeros((1, len(similarities)))\n",
    "comparison_matrix[0] = similarities\n",
    "\n",
    "im = ax2.imshow(comparison_matrix, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)\n",
    "ax2.set_yticks([0])\n",
    "ax2.set_yticklabels(['Query'])\n",
    "ax2.set_xticks(range(len(similarities)))\n",
    "ax2.set_xticklabels([f'R{i+1}' for i in range(len(similarities))])\n",
    "ax2.set_title('Mapa de Calor de Similaridade', fontweight='bold')\n",
    "\n",
    "for i in range(len(similarities)):\n",
    "    ax2.text(i, 0, f'{similarities[i]:.3f}', ha='center', va='center', fontweight='bold')\n",
    "\n",
    "plt.colorbar(im, ax=ax2, label='Similaridade')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Interpretação:\")\n",
    "print(\"\\t- Valores próximos de 1.0 = Alta similaridade\")\n",
    "print(\"\\t- Valores próximos de 0.0 = Baixa similaridade\")\n",
    "print(f\"\\t- Resultado mais similar: {similarities.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b07921",
   "metadata": {},
   "source": [
    "## 7. Experimentos Adicionais - Diferentes Queries\n",
    "\n",
    "Vamos testar a busca semântica com diferentes queries e ver como o sistema responde!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b85df7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diferentes queries para testar\n",
    "test_queries = [\n",
    "    \"pagamentos digitais e bancos\",\n",
    "    \"energia solar e sustentabilidade\",\n",
    "    \"ensino online e educação\",\n",
    "    \"segurança de dados e proteção\"\n",
    "]\n",
    "\n",
    "print(\"TESTANDO MÚLTIPLAS QUERIES:\")\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "for query in test_queries:\n",
    "    # Gerar embedding da query\n",
    "    query_emb = embedding_model.encode(query)\n",
    "    \n",
    "    # Buscar no ChromaDB\n",
    "    search_results = collection.query(\n",
    "        query_embeddings=[query_emb.tolist()],\n",
    "        n_results=1  # Top 1 resultado\n",
    "    )\n",
    "    \n",
    "    # Armazenar resultados\n",
    "    distance_val = search_results['distances'][0][0]\n",
    "    similarity_score = (1 - (distance_val / 2)) * 100\n",
    "    top_result = {\n",
    "        'query': query,\n",
    "        'doc_id': search_results['ids'][0][0],\n",
    "        'title': search_results['metadatas'][0][0]['title'],\n",
    "        'category': search_results['metadatas'][0][0]['category'],\n",
    "        'distance': distance_val,\n",
    "        'similarity_score': similarity_score,\n",
    "        'content': search_results['documents'][0][0][:100]\n",
    "    }\n",
    "    results_summary.append(top_result)\n",
    "    \n",
    "    print(f\"\\nQuery: \\\"{query}\\\"\")\n",
    "    print(f\"\\t- Melhor match: {top_result['title']}\")\n",
    "    print(f\"\\t- Categoria: {top_result['category']}\")\n",
    "    print(f\"\\t- Match Score: {similarity_score:.1f}%\")\n",
    "    print(f\"\\t- Trecho: {top_result['content']}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26fb934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar visualização comparativa\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "queries_short = [q[:30] + '...' if len(q) > 30 else q for q in test_queries]\n",
    "similarity_scores = [r['similarity_score'] for r in results_summary]\n",
    "categories = [r['category'] for r in results_summary]\n",
    "\n",
    "bars = ax.barh(range(len(queries_short)), similarity_scores)\n",
    "\n",
    "# Colorir por categoria\n",
    "category_colors = {cat: plt.cm.Set3(i) for i, cat in enumerate(set(categories))}\n",
    "for bar, cat in zip(bars, categories):\n",
    "    bar.set_color(category_colors[cat])\n",
    "\n",
    "ax.set_yticks(range(len(queries_short)))\n",
    "ax.set_yticklabels(queries_short)\n",
    "ax.set_xlabel('Match Score (%)', fontweight='bold')\n",
    "ax.set_title('Match Score das Queries com Melhor Resultado', fontweight='bold')\n",
    "ax.set_xlim(0, 100)\n",
    "\n",
    "for i, (bar, score, cat) in enumerate(zip(bars, similarity_scores, categories)):\n",
    "    ax.text(score + 2, i, f'{score:.1f}% ({cat})', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d54e448",
   "metadata": {},
   "source": [
    "## 8. Análise de Metadados - Filtragem por Categoria\n",
    "\n",
    "ChromaDB permite filtrar resultados por metadados. Vamos buscar documentos de uma categoria específica!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ae4f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca com filtro de categoria\n",
    "query_filtered = \"tecnologia e inovação\"\n",
    "target_category = \"saude\"\n",
    "\n",
    "print(f\"Query: \\\"{query_filtered}\\\"\")\n",
    "print(f\"Filtrando apenas categoria: {target_category}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e4b4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca SEM filtro\n",
    "results_no_filter = collection.query(\n",
    "    query_embeddings=[embedding_model.encode(query_filtered).tolist()],\n",
    "    n_results=3\n",
    ")\n",
    "\n",
    "# Busca COM filtro\n",
    "results_with_filter = collection.query(\n",
    "    query_embeddings=[embedding_model.encode(query_filtered).tolist()],\n",
    "    n_results=3,\n",
    "    where={\"category\": target_category}  # Filtro por metadado\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd9fa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RESULTADOS SEM FILTRO (Top 3 geral)\")\n",
    "for i in range(len(results_no_filter['ids'][0])):\n",
    "    distance = results_no_filter['distances'][0][i]\n",
    "    similarity_score = (1 - (distance / 2)) * 100\n",
    "    print(f\"{i+1}. {results_no_filter['metadatas'][0][i]['title']}\")\n",
    "    print(f\"\\t- Categoria: {results_no_filter['metadatas'][0][i]['category']}\")\n",
    "    print(f\"\\t- Match Score: {similarity_score:.1f}%\\n\")\n",
    "\n",
    "print(f\"\\nRESULTADOS COM FILTRO (Top 3 em '{target_category}')\")\n",
    "for i in range(len(results_with_filter['ids'][0])):\n",
    "    distance = results_with_filter['distances'][0][i]\n",
    "    similarity_score = (1 - (distance / 2)) * 100\n",
    "    print(f\"{i+1}. {results_with_filter['metadatas'][0][i]['title']}\")\n",
    "    print(f\"\\t- Categoria: {results_with_filter['metadatas'][0][i]['category']}\")\n",
    "    print(f\"\\t- Match Score: {similarity_score:.1f}%\\n\")\n",
    "\n",
    "print(\"Vantagem: Combina busca semântica com filtros estruturados.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
